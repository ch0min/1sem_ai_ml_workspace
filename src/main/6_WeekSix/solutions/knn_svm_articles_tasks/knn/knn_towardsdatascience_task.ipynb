{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Task (`TowardsDataScience Tutorial`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Towardsdatascience tutorial:\n",
    "https://towardsdatascience.com/machine-learning-basics-with-the-knearest-neighbors-algorithm-6a6e71d01761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data.\n",
    "# 2. Initialize K to your chosen number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def knn(data, query, k, distance_fn, choice_fn):\n",
    "    neighbor_distances_and_indices = []\n",
    "    \n",
    "    # 3. For each example in the data.\n",
    "    for index, example in enumerate(data):\n",
    "        # 3.1. Calculate the distance between the query example and the current example from the data.\n",
    "        distance = distance_fn(example[:-1], query)\n",
    "        \n",
    "        # 3.2. Add the distance and the index of the example to an ordered collection.\n",
    "        neighbor_distances_and_indices.append((distance, index))\n",
    "        \n",
    "    # 4. Sort the ordered collection of distances and indices from smallest to largest (in ascending order) by the distances.\n",
    "    sorted_neighbor_distances_and_indices = sorted(neighbor_distances_and_indices)\n",
    "    \n",
    "    # 5. Pick the first K entries from the sorted collection.\n",
    "    k_nearest_distances_and_indices = sorted_neighbor_distances_and_indices[:k]\n",
    "    \n",
    "    # 6. Get the labels of the selected K entries.\n",
    "    k_nearest_labels = [data[i][-1] for distance, i in k_nearest_distances_and_indices]\n",
    "    \n",
    "    # 7. If regression (choice_fn = mean), return the average of the K labels.\n",
    "    # 8. If classification (choice_fn = mode), return the mode of the K labels.\n",
    "    return k_nearest_distances_and_indices, choice_fn(k_nearest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(labels):\n",
    "    return sum(labels) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(labels):\n",
    "    return Counter(labels).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    # sum_squared_distance = 0\n",
    "    # for i in range(len(point1)):\n",
    "    #     sum_squared_distance += math.pow(point1[i] - point2[i], 2)\n",
    "    # return math.sqrt(sum_squared_distance)\n",
    "    return sum ((p1 - p2) ** 2 for p1, p2 in zip(point1, point2)) ** 0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def main():\n",
    "    '''\n",
    "        # Regression Data\n",
    "        #\n",
    "        # Column 0: height (inches)\n",
    "        # Column 1: weight (pounds)\n",
    "    '''\n",
    "    reg_data = [\n",
    "        [65.75, 112.99],\n",
    "        [71.52, 136.49],\n",
    "        [69.40, 153.03],\n",
    "        [68.22, 142.34],\n",
    "        [67.79, 144.30],\n",
    "        [68.70, 123.30],\n",
    "        [69.80, 141.49],\n",
    "        [70.01, 136.46],\n",
    "        [67.90, 112.37],\n",
    "        [65.49, 127.45]\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # Question:\n",
    "        # Given the data we have, what's the best-guess at someone's weight if they are 60 inches tall?\n",
    "    reg_query = [60]\n",
    "    reg_k_nearest_neighbors, reg_prediction = knn(\n",
    "        reg_data, reg_query, k=3, distance_fn=euclidean_distance, choice_fn=mean\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    # Classification Data\n",
    "    #\n",
    "    # Column 0: age\n",
    "    # Column 1: likes pineapple\n",
    "'''\n",
    "clf_data = [\n",
    "    [22, 1],\n",
    "    [23, 1],\n",
    "    [21, 1],\n",
    "    [18, 1],\n",
    "    [19, 1],\n",
    "    [25, 0],\n",
    "    [27, 0],\n",
    "    [29, 0],\n",
    "    [31, 0],\n",
    "    [45, 0]\n",
    "]\n",
    "\n",
    "\n",
    "# Question:\n",
    "    # Given the data we have, does a 33 year old like pineapples on their pizza?\n",
    "clf_query=[33]\n",
    "clf_k_nearest_neighbors, clf_prediction = knn(\n",
    "    clf_data, clf_query, k=3, distance_fn=euclidean_distance, choice_fn=mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation System for the most 5 similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(movie_query, k_recommendations):\n",
    "    raw_movies_data = []\n",
    "    with open(\"./data/movies_recommendation_data.csv\", \"r\") as md:\n",
    "        # Discard the first line (headings).\n",
    "        next(md)\n",
    "        \n",
    "        # Read the data into memory.\n",
    "        for line in md.readlines():\n",
    "            data_row = line.strip().split(\",\")\n",
    "            raw_movies_data.append(data_row)\n",
    "            \n",
    "    # Prepare the data for use in the KNN algorithm by picking \n",
    "    # the relevant columns and converting the numeric columns\n",
    "    # to numbers since they were read in as strings.\n",
    "    movies_recommendation_data = []\n",
    "    for row in raw_movies_data:\n",
    "        data_row = list(map(float, row[2:]))\n",
    "        movies_recommendation_data.append(data_row)\n",
    "\n",
    "    # Use the KNN algorithm to get the 5 movies that are most similar to the movie \"The Post\".\n",
    "    recommendation_indices, _ = knn(\n",
    "        movies_recommendation_data, movie_query, k=k_recommendations,\n",
    "        distance_fn=euclidean_distance, choice_fn=lambda x: None\n",
    "    )\n",
    "    \n",
    "    movie_recommendations = []\n",
    "    for _, index in recommendation_indices:\n",
    "        movie_recommendations.append(raw_movies_data[index])\n",
    "\n",
    "    return movie_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Years a Slave\n",
      "Hacksaw Ridge\n",
      "Queen of Katwe\n",
      "The Wind Rises\n",
      "A Beautiful Mind\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    the_post = [7.2, 1, 1, 0, 0, 0, 0, 1, 0]   # Feature vector for the post\n",
    "    recommended_movies = recommend_movies(movie_query=the_post, k_recommendations=5)\n",
    "    \n",
    "    # Print recommended movie titles.\n",
    "    for recommendation in recommended_movies:\n",
    "        print(recommendation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1sem_ai_ml_workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
