{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLA-4 - Cats and Dogs - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"./data/\"\n",
    "CATEGORIES = [\"cats\", \"dogs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the directory path to the data images as well as resizing:\n",
    "IMG_SIZE = 100\n",
    "data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(DIRECTORY, category)\n",
    "    \n",
    "    # Index of labels\n",
    "    label = CATEGORIES.index(category)\n",
    "    \n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        \n",
    "        # 100 x 100\n",
    "        img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Image with corresponding label to indicate whether it's a cat or dog.\n",
    "        data.append([img_arr, label])\n",
    "        \n",
    "        # plt.imshow(img_arr)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, labels in data:\n",
    "    X.append(features)\n",
    "    y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to numpy:\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data:\n",
    "pickle.dump(X, open(\"X.pkl\", \"wb\"))\n",
    "pickle.dump(y, open(\"y.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Data (Could change to a new notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = pickle.load(open(\"X.pkl\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling since RGB is 0-255:\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.18039216, 0.23529412, 0.27058824],\n",
       "         [0.18431373, 0.23921569, 0.26666667],\n",
       "         [0.19215686, 0.25490196, 0.26666667],\n",
       "         ...,\n",
       "         [0.46666667, 0.47058824, 0.5372549 ],\n",
       "         [0.4627451 , 0.49411765, 0.56862745],\n",
       "         [0.27843137, 0.35686275, 0.38431373]],\n",
       "\n",
       "        [[0.1254902 , 0.20392157, 0.22745098],\n",
       "         [0.15294118, 0.23529412, 0.24313725],\n",
       "         [0.11372549, 0.2       , 0.20392157],\n",
       "         ...,\n",
       "         [0.32156863, 0.37254902, 0.39215686],\n",
       "         [0.29019608, 0.36862745, 0.38431373],\n",
       "         [0.18431373, 0.30588235, 0.3254902 ]],\n",
       "\n",
       "        [[0.16862745, 0.28235294, 0.29803922],\n",
       "         [0.16470588, 0.29019608, 0.28627451],\n",
       "         [0.12156863, 0.24313725, 0.23137255],\n",
       "         ...,\n",
       "         [0.25490196, 0.35686275, 0.34509804],\n",
       "         [0.21960784, 0.33333333, 0.32156863],\n",
       "         [0.13333333, 0.2745098 , 0.2745098 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23921569, 0.34509804, 0.40784314],\n",
       "         [0.28627451, 0.36862745, 0.42745098],\n",
       "         [0.29411765, 0.40784314, 0.44313725],\n",
       "         ...,\n",
       "         [0.27843137, 0.34509804, 0.42745098],\n",
       "         [0.18431373, 0.25490196, 0.32156863],\n",
       "         [0.25490196, 0.32941176, 0.38823529]],\n",
       "\n",
       "        [[0.34509804, 0.44705882, 0.51372549],\n",
       "         [0.21568627, 0.27058824, 0.34509804],\n",
       "         [0.15294118, 0.33333333, 0.35294118],\n",
       "         ...,\n",
       "         [0.35294118, 0.44313725, 0.47058824],\n",
       "         [0.3372549 , 0.40392157, 0.44313725],\n",
       "         [0.21568627, 0.27058824, 0.35686275]],\n",
       "\n",
       "        [[0.29019608, 0.39215686, 0.45490196],\n",
       "         [0.24313725, 0.29019608, 0.35686275],\n",
       "         [0.10588235, 0.31764706, 0.3254902 ],\n",
       "         ...,\n",
       "         [0.20392157, 0.31372549, 0.31764706],\n",
       "         [0.40392157, 0.47843137, 0.50588235],\n",
       "         [0.27058824, 0.3254902 , 0.40392157]]],\n",
       "\n",
       "\n",
       "       [[[0.48235294, 0.54901961, 0.58431373],\n",
       "         [0.49803922, 0.56470588, 0.6       ],\n",
       "         [0.4745098 , 0.54117647, 0.57647059],\n",
       "         ...,\n",
       "         [0.7254902 , 0.7254902 , 0.74901961],\n",
       "         [0.69019608, 0.69019608, 0.71372549],\n",
       "         [0.67843137, 0.67843137, 0.70196078]],\n",
       "\n",
       "        [[0.49411765, 0.56078431, 0.59607843],\n",
       "         [0.50980392, 0.57647059, 0.61176471],\n",
       "         [0.50196078, 0.56862745, 0.60392157],\n",
       "         ...,\n",
       "         [0.70980392, 0.70980392, 0.73333333],\n",
       "         [0.70196078, 0.70196078, 0.7254902 ],\n",
       "         [0.68627451, 0.68627451, 0.70980392]],\n",
       "\n",
       "        [[0.49411765, 0.56470588, 0.6       ],\n",
       "         [0.50196078, 0.56862745, 0.60392157],\n",
       "         [0.50196078, 0.56862745, 0.60392157],\n",
       "         ...,\n",
       "         [0.71372549, 0.71372549, 0.7372549 ],\n",
       "         [0.69019608, 0.69019608, 0.71372549],\n",
       "         [0.68627451, 0.68627451, 0.70980392]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3372549 , 0.38431373, 0.40784314],\n",
       "         [0.34509804, 0.39215686, 0.41568627],\n",
       "         [0.35686275, 0.40392157, 0.42745098],\n",
       "         ...,\n",
       "         [0.41568627, 0.45490196, 0.49411765],\n",
       "         [0.41568627, 0.45490196, 0.49411765],\n",
       "         [0.40784314, 0.45490196, 0.47058824]],\n",
       "\n",
       "        [[0.3254902 , 0.37254902, 0.39607843],\n",
       "         [0.35686275, 0.40392157, 0.42745098],\n",
       "         [0.35686275, 0.40392157, 0.42745098],\n",
       "         ...,\n",
       "         [0.41568627, 0.4627451 , 0.48627451],\n",
       "         [0.40784314, 0.45098039, 0.48235294],\n",
       "         [0.4       , 0.44705882, 0.4627451 ]],\n",
       "\n",
       "        [[0.32941176, 0.37647059, 0.4       ],\n",
       "         [0.33333333, 0.38039216, 0.4       ],\n",
       "         [0.34901961, 0.39607843, 0.41960784],\n",
       "         ...,\n",
       "         [0.4       , 0.44705882, 0.47058824],\n",
       "         [0.40392157, 0.45098039, 0.4745098 ],\n",
       "         [0.4       , 0.44705882, 0.4627451 ]]],\n",
       "\n",
       "\n",
       "       [[[0.20392157, 0.09411765, 0.65098039],\n",
       "         [0.19607843, 0.09411765, 0.63529412],\n",
       "         [0.19607843, 0.09411765, 0.63137255],\n",
       "         ...,\n",
       "         [0.40784314, 0.4745098 , 0.7372549 ],\n",
       "         [0.36078431, 0.39607843, 0.67058824],\n",
       "         [0.23921569, 0.24313725, 0.55686275]],\n",
       "\n",
       "        [[0.19607843, 0.10588235, 0.60392157],\n",
       "         [0.18823529, 0.09019608, 0.61568627],\n",
       "         [0.19607843, 0.09411765, 0.63529412],\n",
       "         ...,\n",
       "         [0.2745098 , 0.28627451, 0.62352941],\n",
       "         [0.35294118, 0.4745098 , 0.62352941],\n",
       "         [0.25490196, 0.38431373, 0.56470588]],\n",
       "\n",
       "        [[0.19607843, 0.10196078, 0.61960784],\n",
       "         [0.19607843, 0.08627451, 0.64705882],\n",
       "         [0.19607843, 0.09411765, 0.63529412],\n",
       "         ...,\n",
       "         [0.20784314, 0.14509804, 0.63529412],\n",
       "         [0.19215686, 0.18039216, 0.55294118],\n",
       "         [0.29411765, 0.32156863, 0.61176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.26666667, 0.1254902 , 0.77647059],\n",
       "         [0.27058824, 0.12941176, 0.78039216],\n",
       "         [0.2627451 , 0.12156863, 0.77254902],\n",
       "         ...,\n",
       "         [0.22745098, 0.17647059, 0.6       ],\n",
       "         [0.21568627, 0.14901961, 0.64313725],\n",
       "         [0.23137255, 0.15686275, 0.6745098 ]],\n",
       "\n",
       "        [[0.22745098, 0.12156863, 0.67058824],\n",
       "         [0.23529412, 0.12156863, 0.69019608],\n",
       "         [0.24705882, 0.1254902 , 0.7254902 ],\n",
       "         ...,\n",
       "         [0.23921569, 0.13333333, 0.72156863],\n",
       "         [0.24313725, 0.12941176, 0.71372549],\n",
       "         [0.23529412, 0.1254902 , 0.70196078]],\n",
       "\n",
       "        [[0.25098039, 0.10980392, 0.68235294],\n",
       "         [0.24313725, 0.10980392, 0.6627451 ],\n",
       "         [0.24313725, 0.11764706, 0.64705882],\n",
       "         ...,\n",
       "         [0.2       , 0.21176471, 0.54509804],\n",
       "         [0.22745098, 0.16078431, 0.66666667],\n",
       "         [0.23529412, 0.14117647, 0.69411765]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.14901961, 0.19215686, 0.24705882],\n",
       "         [0.14901961, 0.19215686, 0.24705882],\n",
       "         [0.14509804, 0.18823529, 0.24313725],\n",
       "         ...,\n",
       "         [0.23529412, 0.37254902, 0.45098039],\n",
       "         [0.23529412, 0.37254902, 0.45098039],\n",
       "         [0.23529412, 0.37254902, 0.45098039]],\n",
       "\n",
       "        [[0.14509804, 0.2       , 0.25490196],\n",
       "         [0.14509804, 0.2       , 0.25490196],\n",
       "         [0.14117647, 0.19607843, 0.25098039],\n",
       "         ...,\n",
       "         [0.23529412, 0.37254902, 0.45098039],\n",
       "         [0.23529412, 0.37254902, 0.45098039],\n",
       "         [0.23529412, 0.37254902, 0.45098039]],\n",
       "\n",
       "        [[0.14117647, 0.20392157, 0.25490196],\n",
       "         [0.14117647, 0.20392157, 0.25490196],\n",
       "         [0.14117647, 0.20392157, 0.25490196],\n",
       "         ...,\n",
       "         [0.23529412, 0.37254902, 0.45098039],\n",
       "         [0.23529412, 0.37254902, 0.45098039],\n",
       "         [0.23529412, 0.37254902, 0.45098039]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.36862745, 0.44313725, 0.50588235],\n",
       "         [0.36470588, 0.42745098, 0.49411765],\n",
       "         [0.38039216, 0.43137255, 0.49019608],\n",
       "         ...,\n",
       "         [0.57254902, 0.23529412, 0.14117647],\n",
       "         [0.58823529, 0.25490196, 0.15686275],\n",
       "         [0.54901961, 0.23921569, 0.14117647]],\n",
       "\n",
       "        [[0.35294118, 0.41176471, 0.48235294],\n",
       "         [0.36078431, 0.41568627, 0.48235294],\n",
       "         [0.36862745, 0.41176471, 0.46666667],\n",
       "         ...,\n",
       "         [0.54901961, 0.21176471, 0.12156863],\n",
       "         [0.55294118, 0.22352941, 0.12941176],\n",
       "         [0.54901961, 0.22745098, 0.13333333]],\n",
       "\n",
       "        [[0.34117647, 0.39607843, 0.47058824],\n",
       "         [0.3372549 , 0.38823529, 0.45490196],\n",
       "         [0.35294118, 0.39607843, 0.45098039],\n",
       "         ...,\n",
       "         [0.59607843, 0.24705882, 0.14901961],\n",
       "         [0.56470588, 0.23137255, 0.12941176],\n",
       "         [0.59215686, 0.2627451 , 0.16078431]]],\n",
       "\n",
       "\n",
       "       [[[0.21176471, 0.23137255, 0.22352941],\n",
       "         [0.20784314, 0.22745098, 0.21960784],\n",
       "         [0.20784314, 0.22745098, 0.21960784],\n",
       "         ...,\n",
       "         [0.00392157, 0.01568627, 0.05098039],\n",
       "         [0.04705882, 0.09019608, 0.16078431],\n",
       "         [0.05490196, 0.14117647, 0.23529412]],\n",
       "\n",
       "        [[0.21568627, 0.23529412, 0.22745098],\n",
       "         [0.19607843, 0.21568627, 0.20784314],\n",
       "         [0.21176471, 0.23137255, 0.22352941],\n",
       "         ...,\n",
       "         [0.03529412, 0.07058824, 0.12156863],\n",
       "         [0.05882353, 0.12156863, 0.20784314],\n",
       "         [0.06666667, 0.15686275, 0.2745098 ]],\n",
       "\n",
       "        [[0.21568627, 0.23529412, 0.22745098],\n",
       "         [0.2       , 0.21960784, 0.21176471],\n",
       "         [0.21176471, 0.23137255, 0.22352941],\n",
       "         ...,\n",
       "         [0.02352941, 0.08627451, 0.14117647],\n",
       "         [0.04313725, 0.12941176, 0.2       ],\n",
       "         [0.06666667, 0.16862745, 0.27058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.18431373, 0.19607843, 0.18823529],\n",
       "         [0.19215686, 0.20392157, 0.19607843],\n",
       "         [0.18431373, 0.19607843, 0.18823529],\n",
       "         ...,\n",
       "         [0.43529412, 0.30980392, 0.25882353],\n",
       "         [0.41176471, 0.28627451, 0.23529412],\n",
       "         [0.38823529, 0.2627451 , 0.21176471]],\n",
       "\n",
       "        [[0.20392157, 0.21568627, 0.20784314],\n",
       "         [0.18431373, 0.19607843, 0.18823529],\n",
       "         [0.17647059, 0.18823529, 0.18039216],\n",
       "         ...,\n",
       "         [0.42352941, 0.29803922, 0.24705882],\n",
       "         [0.41568627, 0.29019608, 0.23921569],\n",
       "         [0.39215686, 0.26666667, 0.21568627]],\n",
       "\n",
       "        [[0.19607843, 0.20784314, 0.2       ],\n",
       "         [0.18823529, 0.2       , 0.19215686],\n",
       "         [0.18431373, 0.19607843, 0.18823529],\n",
       "         ...,\n",
       "         [0.41568627, 0.29019608, 0.23921569],\n",
       "         [0.39607843, 0.27058824, 0.21960784],\n",
       "         [0.39215686, 0.26666667, 0.21568627]]],\n",
       "\n",
       "\n",
       "       [[[0.35686275, 0.29019608, 0.21568627],\n",
       "         [0.36862745, 0.29803922, 0.23137255],\n",
       "         [0.37254902, 0.29803922, 0.23529412],\n",
       "         ...,\n",
       "         [0.36862745, 0.32156863, 0.27058824],\n",
       "         [0.36862745, 0.32941176, 0.2627451 ],\n",
       "         [0.35686275, 0.31764706, 0.25098039]],\n",
       "\n",
       "        [[0.36078431, 0.30196078, 0.23529412],\n",
       "         [0.36078431, 0.30196078, 0.23921569],\n",
       "         [0.36470588, 0.30196078, 0.24705882],\n",
       "         ...,\n",
       "         [0.36078431, 0.31764706, 0.2627451 ],\n",
       "         [0.36078431, 0.31764706, 0.25490196],\n",
       "         [0.35686275, 0.31764706, 0.25098039]],\n",
       "\n",
       "        [[0.35294118, 0.30196078, 0.24705882],\n",
       "         [0.36078431, 0.30588235, 0.25882353],\n",
       "         [0.36470588, 0.30588235, 0.2627451 ],\n",
       "         ...,\n",
       "         [0.35686275, 0.30980392, 0.25882353],\n",
       "         [0.35294118, 0.31372549, 0.24705882],\n",
       "         [0.34117647, 0.30196078, 0.23529412]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.29803922, 0.28235294, 0.23921569],\n",
       "         [0.30196078, 0.28627451, 0.24313725],\n",
       "         [0.30980392, 0.29411765, 0.25098039],\n",
       "         ...,\n",
       "         [0.47843137, 0.45490196, 0.38039216],\n",
       "         [0.49803922, 0.47058824, 0.39607843],\n",
       "         [0.50588235, 0.48235294, 0.40784314]],\n",
       "\n",
       "        [[0.30588235, 0.29019608, 0.24705882],\n",
       "         [0.30980392, 0.29411765, 0.25098039],\n",
       "         [0.30980392, 0.29411765, 0.25098039],\n",
       "         ...,\n",
       "         [0.4745098 , 0.44705882, 0.37254902],\n",
       "         [0.50588235, 0.48235294, 0.40784314],\n",
       "         [0.49411765, 0.47058824, 0.39607843]],\n",
       "\n",
       "        [[0.30588235, 0.29019608, 0.24705882],\n",
       "         [0.31372549, 0.29803922, 0.25490196],\n",
       "         [0.30588235, 0.29019608, 0.24705882],\n",
       "         ...,\n",
       "         [0.48235294, 0.45882353, 0.38431373],\n",
       "         [0.50588235, 0.47843137, 0.40392157],\n",
       "         [0.45490196, 0.43137255, 0.35686275]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now it's 0 to 1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 100, 100, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Img count, width, height, channels:\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "NAME = f\"cats_vs_dogs_prediction_{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs\\\\{NAME}\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markl\\anaconda3\\envs\\ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, input_shape = X.shape[1:], activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 130ms/step - accuracy: 0.4985 - loss: 0.7053 - val_accuracy: 0.5350 - val_loss: 0.6912\n",
      "Epoch 2/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - accuracy: 0.4748 - loss: 0.6932 - val_accuracy: 0.5750 - val_loss: 0.6861\n",
      "Epoch 3/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - accuracy: 0.5485 - loss: 0.6873 - val_accuracy: 0.5900 - val_loss: 0.6678\n",
      "Epoch 4/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.6092 - loss: 0.6618 - val_accuracy: 0.6550 - val_loss: 0.6716\n",
      "Epoch 5/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.6475 - loss: 0.6289 - val_accuracy: 0.6100 - val_loss: 0.6777\n",
      "Epoch 6/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 126ms/step - accuracy: 0.6709 - loss: 0.5932 - val_accuracy: 0.6500 - val_loss: 0.6488\n",
      "Epoch 7/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.7460 - loss: 0.5127 - val_accuracy: 0.6800 - val_loss: 0.6470\n",
      "Epoch 8/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.7750 - loss: 0.4709 - val_accuracy: 0.6650 - val_loss: 0.7980\n",
      "Epoch 9/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - accuracy: 0.8055 - loss: 0.4236 - val_accuracy: 0.6800 - val_loss: 0.7633\n",
      "Epoch 10/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - accuracy: 0.8276 - loss: 0.3464 - val_accuracy: 0.6650 - val_loss: 0.9379\n",
      "Epoch 11/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 124ms/step - accuracy: 0.8628 - loss: 0.3060 - val_accuracy: 0.6650 - val_loss: 0.8094\n",
      "Epoch 12/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.9025 - loss: 0.2213 - val_accuracy: 0.6900 - val_loss: 0.9301\n",
      "Epoch 13/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - accuracy: 0.9460 - loss: 0.1335 - val_accuracy: 0.6900 - val_loss: 1.1820\n",
      "Epoch 14/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.9522 - loss: 0.1240 - val_accuracy: 0.6400 - val_loss: 1.4541\n",
      "Epoch 15/15\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.9449 - loss: 0.1403 - val_accuracy: 0.6850 - val_loss: 1.3441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x277ebb9b470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=15, validation_split=0.1, batch_size=32, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (be inside directory OLA-4) tensorboard --logdir=logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
