{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLA-4 - Cats and Dogs - CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"./data/\"\n",
    "CATEGORIES = [\"cats\", \"dogs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the directory path to the data images as well as resizing:\n",
    "IMG_SIZE = 100\n",
    "data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(DIRECTORY, category)\n",
    "    \n",
    "    # Index of labels\n",
    "    label = CATEGORIES.index(category)\n",
    "    \n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        \n",
    "        # 100 x 100\n",
    "        img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        # Image with corresponding label to indicate whether it's a cat or dog.\n",
    "        data.append([img_arr, label])\n",
    "        \n",
    "        # plt.imshow(img_arr)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, labels in data:\n",
    "    X.append(features)\n",
    "    y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to numpy:\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data:\n",
    "pickle.dump(X, open(\"X.pkl\", \"wb\"))\n",
    "pickle.dump(y, open(\"y.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Data (Could change to a new notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X = pickle.load(open(\"X.pkl\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling since RGB is 0-255:\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.86666667, 1.        , 0.96470588],\n",
       "         [0.82352941, 1.        , 0.96470588],\n",
       "         [0.74509804, 0.96470588, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.76862745, 0.98823529, 0.97647059],\n",
       "         [0.77254902, 0.97647059, 0.98431373],\n",
       "         [0.78431373, 0.98823529, 0.99607843]],\n",
       "\n",
       "        [[0.81960784, 1.        , 0.96470588],\n",
       "         [0.76470588, 0.98039216, 0.94509804],\n",
       "         [0.69803922, 0.94901961, 0.91764706],\n",
       "         ...,\n",
       "         [0.81176471, 0.98431373, 0.98039216],\n",
       "         [0.80784314, 0.98431373, 0.99215686],\n",
       "         [0.82352941, 0.98823529, 1.        ]],\n",
       "\n",
       "        [[0.79607843, 1.        , 0.97647059],\n",
       "         [0.72941176, 0.96862745, 0.92941176],\n",
       "         [0.68235294, 0.94509804, 0.90980392],\n",
       "         ...,\n",
       "         [0.8745098 , 0.98431373, 0.98823529],\n",
       "         [0.85882353, 0.98431373, 1.        ],\n",
       "         [0.87058824, 0.98823529, 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.29019608, 0.49019608, 0.42745098],\n",
       "         [0.21568627, 0.38039216, 0.3372549 ],\n",
       "         [0.1254902 , 0.27058824, 0.23921569],\n",
       "         ...,\n",
       "         [0.09803922, 0.0745098 , 0.04705882],\n",
       "         [0.09411765, 0.07058824, 0.04313725],\n",
       "         [0.09803922, 0.0745098 , 0.04705882]],\n",
       "\n",
       "        [[0.19215686, 0.41568627, 0.35686275],\n",
       "         [0.14509804, 0.3254902 , 0.2745098 ],\n",
       "         [0.23921569, 0.37254902, 0.32941176],\n",
       "         ...,\n",
       "         [0.10980392, 0.08627451, 0.05882353],\n",
       "         [0.09411765, 0.07058824, 0.04313725],\n",
       "         [0.09411765, 0.07058824, 0.04313725]],\n",
       "\n",
       "        [[0.29411765, 0.53333333, 0.47843137],\n",
       "         [0.12156863, 0.30196078, 0.23921569],\n",
       "         [0.2627451 , 0.39607843, 0.33333333],\n",
       "         ...,\n",
       "         [0.10980392, 0.08627451, 0.05882353],\n",
       "         [0.09411765, 0.07058824, 0.04313725],\n",
       "         [0.09411765, 0.07058824, 0.04313725]]],\n",
       "\n",
       "\n",
       "       [[[0.14117647, 0.19215686, 0.25490196],\n",
       "         [0.18823529, 0.22352941, 0.2745098 ],\n",
       "         [0.18039216, 0.20784314, 0.24313725],\n",
       "         ...,\n",
       "         [0.45490196, 0.35686275, 0.22352941],\n",
       "         [0.45882353, 0.35294118, 0.20784314],\n",
       "         [0.43529412, 0.35294118, 0.20392157]],\n",
       "\n",
       "        [[0.0627451 , 0.12156863, 0.19607843],\n",
       "         [0.08235294, 0.13333333, 0.19607843],\n",
       "         [0.09411765, 0.12941176, 0.18039216],\n",
       "         ...,\n",
       "         [0.47058824, 0.37647059, 0.23137255],\n",
       "         [0.47058824, 0.36862745, 0.21176471],\n",
       "         [0.49019608, 0.37254902, 0.21960784]],\n",
       "\n",
       "        [[0.08627451, 0.12156863, 0.16078431],\n",
       "         [0.05882353, 0.09019608, 0.12156863],\n",
       "         [0.04313725, 0.05882353, 0.08235294],\n",
       "         ...,\n",
       "         [0.4745098 , 0.38823529, 0.22745098],\n",
       "         [0.48235294, 0.38431373, 0.21176471],\n",
       "         [0.48627451, 0.38039216, 0.20784314]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.17647059, 0.23137255, 0.38823529],\n",
       "         [0.14509804, 0.21568627, 0.34509804],\n",
       "         [0.1254902 , 0.20784314, 0.32156863],\n",
       "         ...,\n",
       "         [0.59215686, 0.6627451 , 0.71372549],\n",
       "         [0.61960784, 0.68627451, 0.7372549 ],\n",
       "         [0.61568627, 0.69019608, 0.72156863]],\n",
       "\n",
       "        [[0.17647059, 0.22352941, 0.38823529],\n",
       "         [0.14509804, 0.21960784, 0.35686275],\n",
       "         [0.10588235, 0.19215686, 0.30196078],\n",
       "         ...,\n",
       "         [0.60392157, 0.67058824, 0.72156863],\n",
       "         [0.6       , 0.66666667, 0.71764706],\n",
       "         [0.60784314, 0.6745098 , 0.70980392]],\n",
       "\n",
       "        [[0.16470588, 0.22745098, 0.37254902],\n",
       "         [0.14509804, 0.20392157, 0.32941176],\n",
       "         [0.09803922, 0.16470588, 0.26666667],\n",
       "         ...,\n",
       "         [0.58823529, 0.65490196, 0.70588235],\n",
       "         [0.58823529, 0.65490196, 0.70588235],\n",
       "         [0.59215686, 0.6745098 , 0.70588235]]],\n",
       "\n",
       "\n",
       "       [[[0.65490196, 0.6627451 , 0.6627451 ],\n",
       "         [0.64313725, 0.65098039, 0.65098039],\n",
       "         [0.64705882, 0.65490196, 0.65490196],\n",
       "         ...,\n",
       "         [0.6627451 , 0.64313725, 0.63921569],\n",
       "         [0.64313725, 0.62352941, 0.61960784],\n",
       "         [0.64313725, 0.6       , 0.58431373]],\n",
       "\n",
       "        [[0.63921569, 0.63921569, 0.63921569],\n",
       "         [0.64313725, 0.64313725, 0.64313725],\n",
       "         [0.62352941, 0.62352941, 0.62352941],\n",
       "         ...,\n",
       "         [0.65490196, 0.63529412, 0.63137255],\n",
       "         [0.65098039, 0.63137255, 0.62745098],\n",
       "         [0.64313725, 0.61960784, 0.61960784]],\n",
       "\n",
       "        [[0.61568627, 0.59607843, 0.6       ],\n",
       "         [0.62352941, 0.60784314, 0.61176471],\n",
       "         [0.65098039, 0.63529412, 0.63921569],\n",
       "         ...,\n",
       "         [0.64313725, 0.62352941, 0.61960784],\n",
       "         [0.65490196, 0.63529412, 0.63137255],\n",
       "         [0.63921569, 0.62352941, 0.64313725]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6745098 , 0.64705882, 0.63529412],\n",
       "         [0.66666667, 0.63921569, 0.62745098],\n",
       "         [0.67843137, 0.65098039, 0.63921569],\n",
       "         ...,\n",
       "         [0.09019608, 0.07058824, 0.06666667],\n",
       "         [0.08627451, 0.06666667, 0.0627451 ],\n",
       "         [0.08627451, 0.0627451 , 0.06666667]],\n",
       "\n",
       "        [[0.6627451 , 0.63529412, 0.62352941],\n",
       "         [0.65490196, 0.62745098, 0.61568627],\n",
       "         [0.67058824, 0.64313725, 0.63137255],\n",
       "         ...,\n",
       "         [0.08627451, 0.06666667, 0.0627451 ],\n",
       "         [0.08627451, 0.06666667, 0.0627451 ],\n",
       "         [0.07843137, 0.05490196, 0.05882353]],\n",
       "\n",
       "        [[0.65882353, 0.63137255, 0.61960784],\n",
       "         [0.65098039, 0.62352941, 0.61176471],\n",
       "         [0.66666667, 0.63921569, 0.62745098],\n",
       "         ...,\n",
       "         [0.09019608, 0.07058824, 0.06666667],\n",
       "         [0.08627451, 0.06666667, 0.0627451 ],\n",
       "         [0.07843137, 0.05490196, 0.05882353]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.09411765, 0.38039216, 0.73333333],\n",
       "         [0.00392157, 0.14117647, 0.45098039],\n",
       "         [0.17647059, 0.23137255, 0.43137255],\n",
       "         ...,\n",
       "         [0.61568627, 0.72941176, 0.78431373],\n",
       "         [0.60784314, 0.71764706, 0.77647059],\n",
       "         [0.61176471, 0.71764706, 0.78431373]],\n",
       "\n",
       "        [[0.09411765, 0.38431373, 0.73333333],\n",
       "         [0.        , 0.1254902 , 0.43529412],\n",
       "         [0.22352941, 0.27058824, 0.46666667],\n",
       "         ...,\n",
       "         [0.63921569, 0.71372549, 0.78039216],\n",
       "         [0.64705882, 0.71372549, 0.78039216],\n",
       "         [0.65098039, 0.69803922, 0.76862745]],\n",
       "\n",
       "        [[0.09411765, 0.4       , 0.73333333],\n",
       "         [0.        , 0.10980392, 0.40784314],\n",
       "         [0.25882353, 0.29803922, 0.48627451],\n",
       "         ...,\n",
       "         [0.58823529, 0.71372549, 0.79607843],\n",
       "         [0.62352941, 0.7254902 , 0.80392157],\n",
       "         [0.63137255, 0.70980392, 0.78039216]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.31764706, 0.37647059, 0.56078431],\n",
       "         [0.36862745, 0.45490196, 0.63921569],\n",
       "         [0.38823529, 0.45882353, 0.58431373],\n",
       "         ...,\n",
       "         [0.34117647, 0.40392157, 0.54509804],\n",
       "         [0.03921569, 0.09803922, 0.47843137],\n",
       "         [0.        , 0.14901961, 0.61568627]],\n",
       "\n",
       "        [[0.37647059, 0.45098039, 0.63137255],\n",
       "         [0.34117647, 0.44313725, 0.62352941],\n",
       "         [0.34117647, 0.42352941, 0.55686275],\n",
       "         ...,\n",
       "         [0.37254902, 0.45098039, 0.58823529],\n",
       "         [0.07058824, 0.14509804, 0.50588235],\n",
       "         [0.        , 0.14901961, 0.61960784]],\n",
       "\n",
       "        [[0.30196078, 0.4       , 0.57254902],\n",
       "         [0.38823529, 0.49803922, 0.68235294],\n",
       "         [0.35294118, 0.45098039, 0.59607843],\n",
       "         ...,\n",
       "         [0.39215686, 0.48627451, 0.61176471],\n",
       "         [0.21960784, 0.30980392, 0.63529412],\n",
       "         [0.        , 0.15294118, 0.61960784]]],\n",
       "\n",
       "\n",
       "       [[[0.29411765, 0.39607843, 0.42352941],\n",
       "         [0.30980392, 0.42352941, 0.44313725],\n",
       "         [0.30980392, 0.42745098, 0.44705882],\n",
       "         ...,\n",
       "         [0.35294118, 0.36862745, 0.35686275],\n",
       "         [0.44705882, 0.4745098 , 0.4627451 ],\n",
       "         [0.42352941, 0.4745098 , 0.46666667]],\n",
       "\n",
       "        [[0.30588235, 0.40784314, 0.43529412],\n",
       "         [0.32156863, 0.43529412, 0.45490196],\n",
       "         [0.31764706, 0.43529412, 0.45882353],\n",
       "         ...,\n",
       "         [0.44705882, 0.4627451 , 0.45490196],\n",
       "         [0.44313725, 0.4745098 , 0.46666667],\n",
       "         [0.39215686, 0.45098039, 0.43921569]],\n",
       "\n",
       "        [[0.31764706, 0.41960784, 0.44705882],\n",
       "         [0.33333333, 0.44705882, 0.46666667],\n",
       "         [0.33333333, 0.45098039, 0.47058824],\n",
       "         ...,\n",
       "         [0.50588235, 0.51764706, 0.51372549],\n",
       "         [0.45490196, 0.48627451, 0.48235294],\n",
       "         [0.36078431, 0.42352941, 0.41568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.10196078, 0.14509804, 0.17647059],\n",
       "         [0.1254902 , 0.16078431, 0.18823529],\n",
       "         [0.02352941, 0.04313725, 0.0627451 ],\n",
       "         ...,\n",
       "         [0.51764706, 0.52941176, 0.55294118],\n",
       "         [0.21568627, 0.23137255, 0.25098039],\n",
       "         [0.08235294, 0.10588235, 0.11764706]],\n",
       "\n",
       "        [[0.05490196, 0.09411765, 0.1254902 ],\n",
       "         [0.08627451, 0.1254902 , 0.15294118],\n",
       "         [0.19215686, 0.21568627, 0.23529412],\n",
       "         ...,\n",
       "         [0.58039216, 0.60392157, 0.61176471],\n",
       "         [0.59215686, 0.61568627, 0.61568627],\n",
       "         [0.29411765, 0.32941176, 0.31764706]],\n",
       "\n",
       "        [[0.1372549 , 0.18039216, 0.21176471],\n",
       "         [0.09411765, 0.13333333, 0.16470588],\n",
       "         [0.18431373, 0.21176471, 0.22745098],\n",
       "         ...,\n",
       "         [0.54901961, 0.58039216, 0.57647059],\n",
       "         [0.54117647, 0.57647059, 0.56078431],\n",
       "         [0.54509804, 0.59215686, 0.55686275]]],\n",
       "\n",
       "\n",
       "       [[[0.0627451 , 0.05882353, 0.06666667],\n",
       "         [0.0627451 , 0.05882353, 0.06666667],\n",
       "         [0.0627451 , 0.05882353, 0.06666667],\n",
       "         ...,\n",
       "         [0.54117647, 0.58823529, 0.6       ],\n",
       "         [0.5372549 , 0.57254902, 0.60784314],\n",
       "         [0.17647059, 0.20392157, 0.27058824]],\n",
       "\n",
       "        [[0.05490196, 0.05098039, 0.05490196],\n",
       "         [0.03921569, 0.03529412, 0.04313725],\n",
       "         [0.04705882, 0.04313725, 0.05098039],\n",
       "         ...,\n",
       "         [0.54509804, 0.59215686, 0.6       ],\n",
       "         [0.5372549 , 0.57647059, 0.60392157],\n",
       "         [0.19215686, 0.22352941, 0.2745098 ]],\n",
       "\n",
       "        [[0.05098039, 0.04705882, 0.05490196],\n",
       "         [0.07058824, 0.06666667, 0.0745098 ],\n",
       "         [0.07058824, 0.06666667, 0.0745098 ],\n",
       "         ...,\n",
       "         [0.55686275, 0.60784314, 0.6       ],\n",
       "         [0.5372549 , 0.58431373, 0.59607843],\n",
       "         [0.19215686, 0.22745098, 0.2745098 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.62352941, 0.66666667, 0.66666667],\n",
       "         [0.69019608, 0.7372549 , 0.7372549 ],\n",
       "         [0.67843137, 0.7254902 , 0.7254902 ],\n",
       "         ...,\n",
       "         [0.75686275, 0.77647059, 0.77254902],\n",
       "         [0.78039216, 0.8       , 0.79215686],\n",
       "         [0.74901961, 0.76862745, 0.76470588]],\n",
       "\n",
       "        [[0.6627451 , 0.70980392, 0.70980392],\n",
       "         [0.65882353, 0.70588235, 0.70588235],\n",
       "         [0.6745098 , 0.72156863, 0.72156863],\n",
       "         ...,\n",
       "         [0.73333333, 0.75294118, 0.74901961],\n",
       "         [0.77254902, 0.79215686, 0.78823529],\n",
       "         [0.76862745, 0.78823529, 0.78431373]],\n",
       "\n",
       "        [[0.7372549 , 0.78431373, 0.78431373],\n",
       "         [0.73333333, 0.78039216, 0.78039216],\n",
       "         [0.70588235, 0.75294118, 0.75294118],\n",
       "         ...,\n",
       "         [0.77254902, 0.79215686, 0.78823529],\n",
       "         [0.76862745, 0.78823529, 0.78431373],\n",
       "         [0.77647059, 0.79215686, 0.79215686]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now it's 0 to 1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 100, 100, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Img count, width, height, channels:\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "NAME = f\"cats_vs_dogs_prediction_{int(time.time())}\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f\"logs\\\\{NAME}\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, input_shape = X.shape[1:], activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.5107 - loss: 0.6956 - val_accuracy: 0.4550 - val_loss: 0.6998\n",
      "Epoch 2/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - accuracy: 0.5452 - loss: 0.6895 - val_accuracy: 0.5850 - val_loss: 0.6835\n",
      "Epoch 3/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.5929 - loss: 0.6834 - val_accuracy: 0.5800 - val_loss: 0.6817\n",
      "Epoch 4/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.6047 - loss: 0.6607 - val_accuracy: 0.6100 - val_loss: 0.6837\n",
      "Epoch 5/5\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - accuracy: 0.6598 - loss: 0.6197 - val_accuracy: 0.6300 - val_loss: 0.6836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1baa0436ba0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, validation_split=0.1, batch_size=32, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (be inside directory OLA-4) tensorboard --logdir=logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
